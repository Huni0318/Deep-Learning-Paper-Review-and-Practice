{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 논문 제목 : Generative Adversarial Networks **(NIPS2014)**\n",
    "- 학습 데이터셋: **MNIST** (1x28x28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성자(Generator) 및 판별자(Discriminator) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터셋 불러오기\n",
    "- 학습을 위해 MNIST 데이터셋을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e03e9460ab04ba993fa631bb9f10263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb0d916a2cb4f22a4e7da75617d6e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d711f550894dce8a27a2bdc2dc1fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48db33ad1b743e29911613cfa4f16b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 및 샘플링\n",
    "- 학습을 위해 생성자와 판별자 모델을 초기화합니다.\n",
    "- 적절한 하이퍼 파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0002\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.486581] [G loss: 1.368056] [Elapsed time: 3.80s]\n",
      "[Epoch 1/200] [D loss: 0.497844] [G loss: 1.664554] [Elapsed time: 7.37s]\n",
      "[Epoch 2/200] [D loss: 0.392394] [G loss: 0.941869] [Elapsed time: 11.54s]\n",
      "[Epoch 3/200] [D loss: 0.273935] [G loss: 1.256356] [Elapsed time: 14.87s]\n",
      "[Epoch 4/200] [D loss: 0.242697] [G loss: 1.463470] [Elapsed time: 19.29s]\n",
      "[Epoch 5/200] [D loss: 0.569124] [G loss: 0.460970] [Elapsed time: 22.92s]\n",
      "[Epoch 6/200] [D loss: 0.223159] [G loss: 1.789979] [Elapsed time: 26.53s]\n",
      "[Epoch 7/200] [D loss: 0.298815] [G loss: 1.016897] [Elapsed time: 30.18s]\n",
      "[Epoch 8/200] [D loss: 0.190652] [G loss: 2.155183] [Elapsed time: 34.13s]\n",
      "[Epoch 9/200] [D loss: 0.182824] [G loss: 1.661457] [Elapsed time: 38.31s]\n",
      "[Epoch 10/200] [D loss: 0.153939] [G loss: 1.661488] [Elapsed time: 42.35s]\n",
      "[Epoch 11/200] [D loss: 0.195739] [G loss: 2.041120] [Elapsed time: 46.60s]\n",
      "[Epoch 12/200] [D loss: 0.196170] [G loss: 2.417918] [Elapsed time: 51.36s]\n",
      "[Epoch 13/200] [D loss: 0.142232] [G loss: 1.835856] [Elapsed time: 56.06s]\n",
      "[Epoch 14/200] [D loss: 0.452040] [G loss: 0.691534] [Elapsed time: 60.04s]\n",
      "[Epoch 15/200] [D loss: 0.375921] [G loss: 6.666457] [Elapsed time: 63.85s]\n",
      "[Epoch 16/200] [D loss: 0.193876] [G loss: 3.107417] [Elapsed time: 67.47s]\n",
      "[Epoch 17/200] [D loss: 0.211798] [G loss: 1.291617] [Elapsed time: 71.38s]\n",
      "[Epoch 18/200] [D loss: 0.182171] [G loss: 1.903324] [Elapsed time: 75.76s]\n",
      "[Epoch 19/200] [D loss: 0.151565] [G loss: 4.263541] [Elapsed time: 79.86s]\n",
      "[Epoch 20/200] [D loss: 0.254445] [G loss: 1.391534] [Elapsed time: 83.95s]\n",
      "[Epoch 21/200] [D loss: 0.367907] [G loss: 8.366324] [Elapsed time: 88.13s]\n",
      "[Epoch 22/200] [D loss: 0.135410] [G loss: 3.068440] [Elapsed time: 92.40s]\n",
      "[Epoch 23/200] [D loss: 0.385737] [G loss: 5.474126] [Elapsed time: 96.31s]\n",
      "[Epoch 24/200] [D loss: 0.150439] [G loss: 2.216307] [Elapsed time: 100.58s]\n",
      "[Epoch 25/200] [D loss: 0.222502] [G loss: 2.671551] [Elapsed time: 104.37s]\n",
      "[Epoch 26/200] [D loss: 0.137512] [G loss: 2.437533] [Elapsed time: 108.64s]\n",
      "[Epoch 27/200] [D loss: 0.207235] [G loss: 1.541129] [Elapsed time: 113.11s]\n",
      "[Epoch 28/200] [D loss: 0.178960] [G loss: 1.980285] [Elapsed time: 116.96s]\n",
      "[Epoch 29/200] [D loss: 0.251636] [G loss: 4.152716] [Elapsed time: 121.49s]\n",
      "[Epoch 30/200] [D loss: 0.152231] [G loss: 2.133903] [Elapsed time: 125.24s]\n",
      "[Epoch 31/200] [D loss: 0.093157] [G loss: 2.927095] [Elapsed time: 129.36s]\n",
      "[Epoch 32/200] [D loss: 0.108123] [G loss: 2.352643] [Elapsed time: 132.90s]\n",
      "[Epoch 33/200] [D loss: 0.855469] [G loss: 10.510218] [Elapsed time: 136.41s]\n",
      "[Epoch 34/200] [D loss: 0.392919] [G loss: 6.499084] [Elapsed time: 140.20s]\n",
      "[Epoch 35/200] [D loss: 0.110815] [G loss: 2.723859] [Elapsed time: 143.80s]\n",
      "[Epoch 36/200] [D loss: 0.098978] [G loss: 3.219937] [Elapsed time: 147.74s]\n",
      "[Epoch 37/200] [D loss: 0.104782] [G loss: 4.172510] [Elapsed time: 151.61s]\n",
      "[Epoch 38/200] [D loss: 0.219094] [G loss: 1.907924] [Elapsed time: 155.50s]\n",
      "[Epoch 39/200] [D loss: 0.184167] [G loss: 3.099149] [Elapsed time: 158.72s]\n",
      "[Epoch 40/200] [D loss: 0.099476] [G loss: 2.732646] [Elapsed time: 162.82s]\n",
      "[Epoch 41/200] [D loss: 0.163986] [G loss: 3.024907] [Elapsed time: 167.19s]\n",
      "[Epoch 42/200] [D loss: 0.195936] [G loss: 4.797504] [Elapsed time: 170.87s]\n",
      "[Epoch 43/200] [D loss: 0.111195] [G loss: 2.321573] [Elapsed time: 174.79s]\n",
      "[Epoch 44/200] [D loss: 0.848118] [G loss: 8.426417] [Elapsed time: 178.72s]\n",
      "[Epoch 45/200] [D loss: 0.130435] [G loss: 1.975068] [Elapsed time: 182.56s]\n",
      "[Epoch 46/200] [D loss: 0.100944] [G loss: 2.258621] [Elapsed time: 186.18s]\n",
      "[Epoch 47/200] [D loss: 0.288492] [G loss: 3.075497] [Elapsed time: 190.40s]\n",
      "[Epoch 48/200] [D loss: 0.177283] [G loss: 1.932501] [Elapsed time: 194.42s]\n",
      "[Epoch 49/200] [D loss: 0.088166] [G loss: 3.837172] [Elapsed time: 198.34s]\n",
      "[Epoch 50/200] [D loss: 0.211978] [G loss: 2.658489] [Elapsed time: 202.54s]\n",
      "[Epoch 51/200] [D loss: 0.237508] [G loss: 1.114118] [Elapsed time: 206.78s]\n",
      "[Epoch 52/200] [D loss: 0.134907] [G loss: 6.209981] [Elapsed time: 210.46s]\n",
      "[Epoch 53/200] [D loss: 0.119175] [G loss: 3.401318] [Elapsed time: 213.89s]\n",
      "[Epoch 54/200] [D loss: 0.213390] [G loss: 2.076867] [Elapsed time: 217.66s]\n",
      "[Epoch 55/200] [D loss: 0.154852] [G loss: 3.044772] [Elapsed time: 221.36s]\n",
      "[Epoch 56/200] [D loss: 0.126079] [G loss: 2.231408] [Elapsed time: 225.10s]\n",
      "[Epoch 57/200] [D loss: 0.095837] [G loss: 4.877803] [Elapsed time: 228.94s]\n",
      "[Epoch 58/200] [D loss: 0.117312] [G loss: 2.233969] [Elapsed time: 232.95s]\n",
      "[Epoch 59/200] [D loss: 0.195234] [G loss: 1.551622] [Elapsed time: 236.31s]\n",
      "[Epoch 60/200] [D loss: 0.058329] [G loss: 3.706640] [Elapsed time: 239.65s]\n",
      "[Epoch 61/200] [D loss: 0.101695] [G loss: 3.383787] [Elapsed time: 243.58s]\n",
      "[Epoch 62/200] [D loss: 0.142259] [G loss: 2.920439] [Elapsed time: 247.59s]\n",
      "[Epoch 63/200] [D loss: 0.275646] [G loss: 1.158700] [Elapsed time: 251.64s]\n",
      "[Epoch 64/200] [D loss: 0.090755] [G loss: 4.774991] [Elapsed time: 255.74s]\n",
      "[Epoch 65/200] [D loss: 0.373914] [G loss: 1.985657] [Elapsed time: 259.39s]\n",
      "[Epoch 66/200] [D loss: 0.300395] [G loss: 5.417150] [Elapsed time: 263.49s]\n",
      "[Epoch 67/200] [D loss: 0.120693] [G loss: 4.860080] [Elapsed time: 267.85s]\n",
      "[Epoch 68/200] [D loss: 0.179906] [G loss: 4.015377] [Elapsed time: 271.46s]\n",
      "[Epoch 69/200] [D loss: 0.131812] [G loss: 3.986974] [Elapsed time: 275.06s]\n",
      "[Epoch 70/200] [D loss: 0.111513] [G loss: 3.335303] [Elapsed time: 278.95s]\n",
      "[Epoch 71/200] [D loss: 0.079551] [G loss: 3.494746] [Elapsed time: 283.14s]\n",
      "[Epoch 72/200] [D loss: 0.113278] [G loss: 4.936925] [Elapsed time: 287.13s]\n",
      "[Epoch 73/200] [D loss: 0.144472] [G loss: 4.234518] [Elapsed time: 291.55s]\n",
      "[Epoch 74/200] [D loss: 0.125046] [G loss: 3.476562] [Elapsed time: 296.09s]\n",
      "[Epoch 75/200] [D loss: 0.141108] [G loss: 3.243012] [Elapsed time: 299.99s]\n",
      "[Epoch 76/200] [D loss: 0.164756] [G loss: 3.273309] [Elapsed time: 304.01s]\n",
      "[Epoch 77/200] [D loss: 0.263507] [G loss: 1.832322] [Elapsed time: 307.68s]\n",
      "[Epoch 78/200] [D loss: 0.100751] [G loss: 2.658382] [Elapsed time: 311.29s]\n",
      "[Epoch 79/200] [D loss: 0.118616] [G loss: 1.920291] [Elapsed time: 314.89s]\n",
      "[Epoch 80/200] [D loss: 0.121844] [G loss: 2.437835] [Elapsed time: 318.61s]\n",
      "[Epoch 81/200] [D loss: 0.163512] [G loss: 2.671543] [Elapsed time: 322.22s]\n",
      "[Epoch 82/200] [D loss: 0.076768] [G loss: 2.792588] [Elapsed time: 325.69s]\n",
      "[Epoch 83/200] [D loss: 0.173432] [G loss: 2.904985] [Elapsed time: 329.64s]\n",
      "[Epoch 84/200] [D loss: 0.239398] [G loss: 1.566274] [Elapsed time: 333.65s]\n",
      "[Epoch 85/200] [D loss: 0.167793] [G loss: 4.506850] [Elapsed time: 337.34s]\n",
      "[Epoch 86/200] [D loss: 0.283805] [G loss: 6.730336] [Elapsed time: 341.78s]\n",
      "[Epoch 87/200] [D loss: 0.098722] [G loss: 2.643781] [Elapsed time: 345.74s]\n",
      "[Epoch 88/200] [D loss: 0.049551] [G loss: 3.003026] [Elapsed time: 349.85s]\n",
      "[Epoch 89/200] [D loss: 0.212306] [G loss: 2.525533] [Elapsed time: 353.85s]\n",
      "[Epoch 90/200] [D loss: 0.130686] [G loss: 3.033092] [Elapsed time: 357.81s]\n",
      "[Epoch 91/200] [D loss: 0.116695] [G loss: 2.628031] [Elapsed time: 361.67s]\n",
      "[Epoch 92/200] [D loss: 0.193989] [G loss: 1.696694] [Elapsed time: 365.14s]\n",
      "[Epoch 93/200] [D loss: 0.179753] [G loss: 2.619269] [Elapsed time: 369.04s]\n",
      "[Epoch 94/200] [D loss: 0.352729] [G loss: 1.420901] [Elapsed time: 372.67s]\n",
      "[Epoch 95/200] [D loss: 0.146355] [G loss: 2.150595] [Elapsed time: 376.73s]\n",
      "[Epoch 96/200] [D loss: 0.141379] [G loss: 2.074925] [Elapsed time: 380.33s]\n",
      "[Epoch 97/200] [D loss: 0.136062] [G loss: 2.213435] [Elapsed time: 383.54s]\n",
      "[Epoch 98/200] [D loss: 0.136579] [G loss: 2.258106] [Elapsed time: 387.61s]\n",
      "[Epoch 99/200] [D loss: 0.183360] [G loss: 2.296261] [Elapsed time: 390.91s]\n",
      "[Epoch 100/200] [D loss: 0.242238] [G loss: 2.008642] [Elapsed time: 395.36s]\n",
      "[Epoch 101/200] [D loss: 0.217097] [G loss: 2.868551] [Elapsed time: 399.52s]\n",
      "[Epoch 102/200] [D loss: 0.195036] [G loss: 4.809810] [Elapsed time: 403.35s]\n",
      "[Epoch 103/200] [D loss: 0.108564] [G loss: 2.808196] [Elapsed time: 406.77s]\n",
      "[Epoch 104/200] [D loss: 0.363848] [G loss: 1.376041] [Elapsed time: 410.24s]\n",
      "[Epoch 105/200] [D loss: 0.202082] [G loss: 2.089292] [Elapsed time: 413.85s]\n",
      "[Epoch 106/200] [D loss: 0.288693] [G loss: 1.318605] [Elapsed time: 417.90s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107/200] [D loss: 0.201085] [G loss: 2.968145] [Elapsed time: 421.96s]\n",
      "[Epoch 108/200] [D loss: 0.202341] [G loss: 3.181297] [Elapsed time: 426.63s]\n",
      "[Epoch 109/200] [D loss: 0.403483] [G loss: 5.893050] [Elapsed time: 430.37s]\n",
      "[Epoch 110/200] [D loss: 0.213820] [G loss: 3.482172] [Elapsed time: 434.28s]\n",
      "[Epoch 111/200] [D loss: 0.195472] [G loss: 2.326869] [Elapsed time: 437.90s]\n",
      "[Epoch 112/200] [D loss: 0.112737] [G loss: 3.808080] [Elapsed time: 441.17s]\n",
      "[Epoch 113/200] [D loss: 0.191946] [G loss: 2.398831] [Elapsed time: 445.44s]\n",
      "[Epoch 114/200] [D loss: 0.161883] [G loss: 2.556035] [Elapsed time: 448.89s]\n",
      "[Epoch 115/200] [D loss: 0.219189] [G loss: 3.722498] [Elapsed time: 452.80s]\n",
      "[Epoch 116/200] [D loss: 0.067845] [G loss: 2.932688] [Elapsed time: 456.91s]\n",
      "[Epoch 117/200] [D loss: 0.261448] [G loss: 4.578887] [Elapsed time: 460.65s]\n",
      "[Epoch 118/200] [D loss: 0.147605] [G loss: 2.677481] [Elapsed time: 464.84s]\n",
      "[Epoch 119/200] [D loss: 0.194250] [G loss: 1.834552] [Elapsed time: 468.40s]\n",
      "[Epoch 120/200] [D loss: 0.187607] [G loss: 3.354803] [Elapsed time: 472.38s]\n",
      "[Epoch 121/200] [D loss: 0.132710] [G loss: 2.474435] [Elapsed time: 476.05s]\n",
      "[Epoch 122/200] [D loss: 0.144880] [G loss: 2.251001] [Elapsed time: 479.60s]\n",
      "[Epoch 123/200] [D loss: 0.079363] [G loss: 2.852177] [Elapsed time: 483.54s]\n",
      "[Epoch 124/200] [D loss: 0.225296] [G loss: 4.515674] [Elapsed time: 487.38s]\n",
      "[Epoch 125/200] [D loss: 0.084368] [G loss: 2.553790] [Elapsed time: 491.61s]\n",
      "[Epoch 126/200] [D loss: 0.094003] [G loss: 2.717824] [Elapsed time: 495.60s]\n",
      "[Epoch 127/200] [D loss: 0.114124] [G loss: 2.714192] [Elapsed time: 499.44s]\n",
      "[Epoch 128/200] [D loss: 0.119332] [G loss: 2.774838] [Elapsed time: 503.47s]\n",
      "[Epoch 129/200] [D loss: 0.189347] [G loss: 3.031911] [Elapsed time: 507.64s]\n",
      "[Epoch 130/200] [D loss: 0.211215] [G loss: 3.366054] [Elapsed time: 511.31s]\n",
      "[Epoch 131/200] [D loss: 0.218432] [G loss: 2.203513] [Elapsed time: 514.75s]\n",
      "[Epoch 132/200] [D loss: 0.280726] [G loss: 1.206225] [Elapsed time: 518.25s]\n",
      "[Epoch 133/200] [D loss: 0.123238] [G loss: 2.190311] [Elapsed time: 521.93s]\n",
      "[Epoch 134/200] [D loss: 0.119464] [G loss: 3.445457] [Elapsed time: 526.13s]\n",
      "[Epoch 135/200] [D loss: 0.171020] [G loss: 1.961719] [Elapsed time: 530.40s]\n",
      "[Epoch 136/200] [D loss: 0.177362] [G loss: 3.064690] [Elapsed time: 534.29s]\n",
      "[Epoch 137/200] [D loss: 0.304613] [G loss: 1.816175] [Elapsed time: 538.01s]\n",
      "[Epoch 138/200] [D loss: 0.282607] [G loss: 4.613625] [Elapsed time: 541.93s]\n",
      "[Epoch 139/200] [D loss: 0.115914] [G loss: 2.932266] [Elapsed time: 545.50s]\n",
      "[Epoch 140/200] [D loss: 0.106763] [G loss: 2.994859] [Elapsed time: 549.81s]\n",
      "[Epoch 141/200] [D loss: 0.274323] [G loss: 4.000899] [Elapsed time: 553.70s]\n",
      "[Epoch 142/200] [D loss: 0.131152] [G loss: 2.634041] [Elapsed time: 558.09s]\n",
      "[Epoch 143/200] [D loss: 0.120439] [G loss: 2.271293] [Elapsed time: 562.15s]\n",
      "[Epoch 144/200] [D loss: 0.260084] [G loss: 2.668575] [Elapsed time: 566.24s]\n",
      "[Epoch 145/200] [D loss: 0.146701] [G loss: 3.383270] [Elapsed time: 570.39s]\n",
      "[Epoch 146/200] [D loss: 0.191363] [G loss: 3.144812] [Elapsed time: 574.17s]\n",
      "[Epoch 147/200] [D loss: 0.216974] [G loss: 3.141096] [Elapsed time: 578.00s]\n",
      "[Epoch 148/200] [D loss: 0.199070] [G loss: 3.673676] [Elapsed time: 581.71s]\n",
      "[Epoch 149/200] [D loss: 0.131851] [G loss: 2.992273] [Elapsed time: 585.11s]\n",
      "[Epoch 150/200] [D loss: 0.187866] [G loss: 2.006631] [Elapsed time: 589.02s]\n",
      "[Epoch 151/200] [D loss: 0.280692] [G loss: 3.651589] [Elapsed time: 592.75s]\n",
      "[Epoch 152/200] [D loss: 0.198478] [G loss: 2.425477] [Elapsed time: 596.13s]\n",
      "[Epoch 153/200] [D loss: 0.173901] [G loss: 2.552402] [Elapsed time: 600.67s]\n",
      "[Epoch 154/200] [D loss: 0.170182] [G loss: 2.662509] [Elapsed time: 604.88s]\n",
      "[Epoch 155/200] [D loss: 0.170447] [G loss: 4.142737] [Elapsed time: 608.84s]\n",
      "[Epoch 156/200] [D loss: 0.137924] [G loss: 1.909320] [Elapsed time: 612.98s]\n",
      "[Epoch 157/200] [D loss: 0.148722] [G loss: 2.461119] [Elapsed time: 617.01s]\n",
      "[Epoch 158/200] [D loss: 0.257927] [G loss: 1.876484] [Elapsed time: 620.74s]\n",
      "[Epoch 159/200] [D loss: 0.262187] [G loss: 1.630924] [Elapsed time: 624.21s]\n",
      "[Epoch 160/200] [D loss: 0.268854] [G loss: 1.664324] [Elapsed time: 627.54s]\n",
      "[Epoch 161/200] [D loss: 0.117750] [G loss: 3.103231] [Elapsed time: 631.20s]\n",
      "[Epoch 162/200] [D loss: 0.116377] [G loss: 3.001879] [Elapsed time: 635.14s]\n",
      "[Epoch 163/200] [D loss: 0.156701] [G loss: 5.302564] [Elapsed time: 639.84s]\n",
      "[Epoch 164/200] [D loss: 0.299975] [G loss: 4.386250] [Elapsed time: 644.28s]\n",
      "[Epoch 165/200] [D loss: 0.130407] [G loss: 3.571942] [Elapsed time: 648.62s]\n",
      "[Epoch 166/200] [D loss: 0.086565] [G loss: 2.732524] [Elapsed time: 652.18s]\n",
      "[Epoch 167/200] [D loss: 0.080176] [G loss: 3.425224] [Elapsed time: 655.55s]\n",
      "[Epoch 168/200] [D loss: 0.328688] [G loss: 3.499714] [Elapsed time: 660.17s]\n",
      "[Epoch 169/200] [D loss: 0.104361] [G loss: 3.063130] [Elapsed time: 664.36s]\n",
      "[Epoch 170/200] [D loss: 0.134604] [G loss: 4.775442] [Elapsed time: 668.40s]\n",
      "[Epoch 171/200] [D loss: 0.110566] [G loss: 2.926893] [Elapsed time: 672.13s]\n",
      "[Epoch 172/200] [D loss: 0.100632] [G loss: 2.615209] [Elapsed time: 675.44s]\n",
      "[Epoch 173/200] [D loss: 0.189428] [G loss: 3.761658] [Elapsed time: 678.59s]\n",
      "[Epoch 174/200] [D loss: 0.129187] [G loss: 2.397433] [Elapsed time: 681.96s]\n",
      "[Epoch 175/200] [D loss: 0.229297] [G loss: 2.322446] [Elapsed time: 685.71s]\n",
      "[Epoch 176/200] [D loss: 0.149660] [G loss: 3.255666] [Elapsed time: 689.11s]\n",
      "[Epoch 177/200] [D loss: 0.303976] [G loss: 5.982856] [Elapsed time: 693.62s]\n",
      "[Epoch 178/200] [D loss: 0.111080] [G loss: 3.874144] [Elapsed time: 697.33s]\n",
      "[Epoch 179/200] [D loss: 0.088085] [G loss: 3.018755] [Elapsed time: 701.34s]\n",
      "[Epoch 180/200] [D loss: 0.161231] [G loss: 3.124340] [Elapsed time: 705.55s]\n",
      "[Epoch 181/200] [D loss: 0.154224] [G loss: 3.719299] [Elapsed time: 709.28s]\n",
      "[Epoch 182/200] [D loss: 0.184804] [G loss: 4.361478] [Elapsed time: 712.84s]\n",
      "[Epoch 183/200] [D loss: 0.144925] [G loss: 2.434083] [Elapsed time: 717.00s]\n",
      "[Epoch 184/200] [D loss: 0.156034] [G loss: 3.969187] [Elapsed time: 721.59s]\n",
      "[Epoch 185/200] [D loss: 0.170320] [G loss: 2.888864] [Elapsed time: 724.97s]\n",
      "[Epoch 186/200] [D loss: 0.188360] [G loss: 2.462130] [Elapsed time: 728.86s]\n",
      "[Epoch 187/200] [D loss: 0.190957] [G loss: 1.949760] [Elapsed time: 733.23s]\n",
      "[Epoch 188/200] [D loss: 0.134510] [G loss: 4.649998] [Elapsed time: 737.27s]\n",
      "[Epoch 189/200] [D loss: 0.192005] [G loss: 3.597908] [Elapsed time: 741.17s]\n",
      "[Epoch 190/200] [D loss: 0.184095] [G loss: 2.462813] [Elapsed time: 744.65s]\n",
      "[Epoch 191/200] [D loss: 0.260465] [G loss: 4.511989] [Elapsed time: 747.97s]\n",
      "[Epoch 192/200] [D loss: 0.303807] [G loss: 1.576926] [Elapsed time: 751.64s]\n",
      "[Epoch 193/200] [D loss: 0.154345] [G loss: 2.923513] [Elapsed time: 755.50s]\n",
      "[Epoch 194/200] [D loss: 0.147044] [G loss: 2.950782] [Elapsed time: 760.36s]\n",
      "[Epoch 195/200] [D loss: 0.110820] [G loss: 3.357954] [Elapsed time: 764.04s]\n",
      "[Epoch 196/200] [D loss: 0.097104] [G loss: 3.091433] [Elapsed time: 767.89s]\n",
      "[Epoch 197/200] [D loss: 0.128973] [G loss: 3.892167] [Elapsed time: 771.82s]\n",
      "[Epoch 198/200] [D loss: 0.150832] [G loss: 4.766391] [Elapsed time: 775.38s]\n",
      "[Epoch 199/200] [D loss: 0.138338] [G loss: 2.855981] [Elapsed time: 779.51s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 2000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생성된 이미지 예시를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b84687227081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'92000.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Image' object has no attribute 'resize'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "img = Image.open('../sample.png')\n",
    "\n",
    "Image('92000.png').resize(1,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
